{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa2d6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM not imported.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to sys.path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "# Now import\n",
    "from ares import ARES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc52d2a9",
   "metadata": {},
   "source": [
    "### Context Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3e9587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: 'assigned_batch_size' not provided for classifier_model, using default value 1.\n",
      "\n",
      "Warning: 'gradient_accumulation_multiplier' not provided for classifier_model, using default value 32.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/218 [00:00<?, ? examples/s]Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 218/218 [00:00<00:00, 2441.31 examples/s]\n",
      "Map: 100%|██████████| 29/29 [00:00<00:00, 2319.90 examples/s]\n",
      "Map: 100%|██████████| 29/29 [00:00<00:00, 2319.37 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "Checkpoint Path: checkpoints/microsoft-deberta-v3-large/Context_Relevance_Label_None_2025-06-11_15-49-31.pt\n",
      "Beginning Training\n",
      "Current Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [00:47<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0/100] train_loss: 0.69253 valid_loss: 0.68629\n",
      "Validation loss decreased (inf --> 0.686293).  Saving model ...\n",
      "Current Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:08<00:00,  3.24it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/100] train_loss: 0.69710 valid_loss: 0.68903\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Current Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.32it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2/100] train_loss: 0.68520 valid_loss: 0.68651\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Current Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.26it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3/100] train_loss: 0.68749 valid_loss: 0.69102\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Current Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.27it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4/100] train_loss: 0.68555 valid_loss: 0.69554\n",
      "EarlyStopping counter: 4 out of 50\n",
      "Current Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.11it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5/100] train_loss: 0.69051 valid_loss: 0.69801\n",
      "EarlyStopping counter: 5 out of 50\n",
      "Current Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.23it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6/100] train_loss: 0.68554 valid_loss: 0.64923\n",
      "Validation loss decreased (0.686293 --> 0.649225).  Saving model ...\n",
      "Current Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:09<00:00,  3.18it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7/100] train_loss: 0.67697 valid_loss: 0.70672\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Current Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.79it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8/100] train_loss: 0.68621 valid_loss: 0.70783\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Current Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.78it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9/100] train_loss: 0.69356 valid_loss: 0.70865\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Current Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.78it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10/100] train_loss: 0.69592 valid_loss: 0.70751\n",
      "EarlyStopping counter: 4 out of 50\n",
      "Current Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.27it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11/100] train_loss: 0.69361 valid_loss: 0.70522\n",
      "EarlyStopping counter: 5 out of 50\n",
      "Current Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.24it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12/100] train_loss: 0.68737 valid_loss: 0.70257\n",
      "EarlyStopping counter: 6 out of 50\n",
      "Current Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 12.97it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13/100] train_loss: 0.69824 valid_loss: 0.70020\n",
      "EarlyStopping counter: 7 out of 50\n",
      "Current Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.20it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14/100] train_loss: 0.69073 valid_loss: 0.69822\n",
      "EarlyStopping counter: 8 out of 50\n",
      "Current Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.27it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 15/100] train_loss: 0.69571 valid_loss: 0.69696\n",
      "EarlyStopping counter: 9 out of 50\n",
      "Current Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.25it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 16/100] train_loss: 0.68901 valid_loss: 0.69600\n",
      "EarlyStopping counter: 10 out of 50\n",
      "Current Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.26it/s]\n",
      "100%|██████████| 218/218 [00:46<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17/100] train_loss: 0.68925 valid_loss: 0.69329\n",
      "EarlyStopping counter: 11 out of 50\n",
      "Current Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.79it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18/100] train_loss: 0.67600 valid_loss: 0.60923\n",
      "Validation loss decreased (0.649225 --> 0.609227).  Saving model ...\n",
      "Current Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:08<00:00,  3.28it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 19/100] train_loss: 0.57580 valid_loss: 0.56694\n",
      "Validation loss decreased (0.609227 --> 0.566940).  Saving model ...\n",
      "Current Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:08<00:00,  3.30it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20/100] train_loss: 0.54882 valid_loss: 0.60366\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Current Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.76it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21/100] train_loss: 0.50793 valid_loss: 0.59877\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Current Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.76it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22/100] train_loss: 0.44588 valid_loss: 0.56740\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Current Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.67it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23/100] train_loss: 0.38035 valid_loss: 0.63444\n",
      "EarlyStopping counter: 4 out of 50\n",
      "Current Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.75it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24/100] train_loss: 0.32784 valid_loss: 0.62851\n",
      "EarlyStopping counter: 5 out of 50\n",
      "Current Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.75it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 25/100] train_loss: 0.28589 valid_loss: 0.82886\n",
      "EarlyStopping counter: 6 out of 50\n",
      "Current Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.77it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 26/100] train_loss: 0.21715 valid_loss: 0.87799\n",
      "EarlyStopping counter: 7 out of 50\n",
      "Current Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.78it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27/100] train_loss: 0.25616 valid_loss: 0.89171\n",
      "EarlyStopping counter: 8 out of 50\n",
      "Current Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.62it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 28/100] train_loss: 0.30780 valid_loss: 0.85211\n",
      "EarlyStopping counter: 9 out of 50\n",
      "Current Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.74it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 29/100] train_loss: 0.16935 valid_loss: 1.05615\n",
      "EarlyStopping counter: 10 out of 50\n",
      "Current Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.75it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30/100] train_loss: 0.13463 valid_loss: 1.11779\n",
      "EarlyStopping counter: 11 out of 50\n",
      "Current Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.75it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 31/100] train_loss: 0.11153 valid_loss: 1.00148\n",
      "EarlyStopping counter: 12 out of 50\n",
      "Current Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.76it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 32/100] train_loss: 0.07258 valid_loss: 1.01871\n",
      "EarlyStopping counter: 13 out of 50\n",
      "Current Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.77it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 33/100] train_loss: 0.02674 valid_loss: 1.08577\n",
      "EarlyStopping counter: 14 out of 50\n",
      "Current Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.76it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 34/100] train_loss: 0.01733 valid_loss: 1.08624\n",
      "EarlyStopping counter: 15 out of 50\n",
      "Current Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.76it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 35/100] train_loss: 0.01514 valid_loss: 1.51528\n",
      "EarlyStopping counter: 16 out of 50\n",
      "Current Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.70it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 36/100] train_loss: 0.01363 valid_loss: 1.43503\n",
      "EarlyStopping counter: 17 out of 50\n",
      "Current Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.74it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 37/100] train_loss: 0.03258 valid_loss: 1.17970\n",
      "EarlyStopping counter: 18 out of 50\n",
      "Current Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.73it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 38/100] train_loss: 0.00560 valid_loss: 1.34557\n",
      "EarlyStopping counter: 19 out of 50\n",
      "Current Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.73it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 39/100] train_loss: 0.03550 valid_loss: 1.49731\n",
      "EarlyStopping counter: 20 out of 50\n",
      "Current Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.75it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 40/100] train_loss: 0.00725 valid_loss: 1.47802\n",
      "EarlyStopping counter: 21 out of 50\n",
      "Current Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.77it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 41/100] train_loss: 0.01961 valid_loss: 1.67896\n",
      "EarlyStopping counter: 22 out of 50\n",
      "Current Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.18it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 42/100] train_loss: 0.01476 valid_loss: 1.66117\n",
      "EarlyStopping counter: 23 out of 50\n",
      "Current Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.14it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 43/100] train_loss: 0.01059 valid_loss: 1.60361\n",
      "EarlyStopping counter: 24 out of 50\n",
      "Current Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 12.99it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 44/100] train_loss: 0.00633 valid_loss: 1.56509\n",
      "EarlyStopping counter: 25 out of 50\n",
      "Current Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.02it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 45/100] train_loss: 0.00237 valid_loss: 1.57510\n",
      "EarlyStopping counter: 26 out of 50\n",
      "Current Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 12.95it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 46/100] train_loss: 0.00265 valid_loss: 1.62744\n",
      "EarlyStopping counter: 27 out of 50\n",
      "Current Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.13it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 47/100] train_loss: 0.00166 valid_loss: 1.67269\n",
      "EarlyStopping counter: 28 out of 50\n",
      "Current Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.20it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 48/100] train_loss: 0.00255 valid_loss: 1.73767\n",
      "EarlyStopping counter: 29 out of 50\n",
      "Current Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.22it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 49/100] train_loss: 0.00170 valid_loss: 1.80592\n",
      "EarlyStopping counter: 30 out of 50\n",
      "Current Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 12.98it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50/100] train_loss: 0.00201 valid_loss: 1.88712\n",
      "EarlyStopping counter: 31 out of 50\n",
      "Current Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.13it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 51/100] train_loss: 0.00115 valid_loss: 1.92596\n",
      "EarlyStopping counter: 32 out of 50\n",
      "Current Epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 12.97it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 52/100] train_loss: 0.00127 valid_loss: 1.94312\n",
      "EarlyStopping counter: 33 out of 50\n",
      "Current Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.22it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 53/100] train_loss: 0.00088 valid_loss: 1.96112\n",
      "EarlyStopping counter: 34 out of 50\n",
      "Current Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.23it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 54/100] train_loss: 0.00080 valid_loss: 1.97690\n",
      "EarlyStopping counter: 35 out of 50\n",
      "Current Epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.27it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 55/100] train_loss: 0.00087 valid_loss: 1.99063\n",
      "EarlyStopping counter: 36 out of 50\n",
      "Current Epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 12.99it/s]\n",
      "100%|██████████| 218/218 [00:47<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 56/100] train_loss: 0.00101 valid_loss: 1.99280\n",
      "EarlyStopping counter: 37 out of 50\n",
      "Current Epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.22it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 57/100] train_loss: 0.00067 valid_loss: 1.97478\n",
      "EarlyStopping counter: 38 out of 50\n",
      "Current Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.76it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 58/100] train_loss: 0.00061 valid_loss: 1.96456\n",
      "EarlyStopping counter: 39 out of 50\n",
      "Current Epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.71it/s]\n",
      "100%|██████████| 218/218 [00:46<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 59/100] train_loss: 0.00056 valid_loss: 1.96159\n",
      "EarlyStopping counter: 40 out of 50\n",
      "Current Epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.75it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 60/100] train_loss: 0.00055 valid_loss: 1.96445\n",
      "EarlyStopping counter: 41 out of 50\n",
      "Current Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.68it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 61/100] train_loss: 0.00060 valid_loss: 1.97247\n",
      "EarlyStopping counter: 42 out of 50\n",
      "Current Epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.77it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 62/100] train_loss: 0.00050 valid_loss: 1.98273\n",
      "EarlyStopping counter: 43 out of 50\n",
      "Current Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.77it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 63/100] train_loss: 0.00047 valid_loss: 1.99321\n",
      "EarlyStopping counter: 44 out of 50\n",
      "Current Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.76it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 64/100] train_loss: 0.00048 valid_loss: 2.00356\n",
      "EarlyStopping counter: 45 out of 50\n",
      "Current Epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.75it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 65/100] train_loss: 0.00050 valid_loss: 2.01411\n",
      "EarlyStopping counter: 46 out of 50\n",
      "Current Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.77it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 66/100] train_loss: 0.00045 valid_loss: 2.02575\n",
      "EarlyStopping counter: 47 out of 50\n",
      "Current Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.74it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 67/100] train_loss: 0.00039 valid_loss: 2.03723\n",
      "EarlyStopping counter: 48 out of 50\n",
      "Current Epoch: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.77it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 68/100] train_loss: 0.00119 valid_loss: 2.04850\n",
      "EarlyStopping counter: 49 out of 50\n",
      "Current Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.65it/s]\n",
      "100%|██████████| 218/218 [00:45<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 69/100] train_loss: 0.00045 valid_loss: 2.15820\n",
      "EarlyStopping counter: 50 out of 50\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31m2025/06/11 16:46:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "100%|██████████| 29/29 [00:21<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Best Model\n",
      "Beginning Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Predictions and Reference Shapes\n",
      "torch.Size([29])\n",
      "torch.Size([29])\n",
      "Accuracy for Test Set: 0.8275862068965517\n",
      "Macro Precision: 89.13\n",
      "Macro Recall:    77.27\n",
      "Macro F1:        79.20\n",
      "Micro Precision: 82.76\n",
      "Micro Recall:    82.76\n",
      "Micro F1:        82.76\n",
      "Positive / Negative Reference Ratio: 0.379\n",
      "Saved classification checkpoint to: checkpoints/microsoft-deberta-v3-large/Context_Relevance_Label_None_2025-06-11_15-49-31.pt\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifier_config = {\n",
    "    \"training_dataset\": [\"../datasets_file/output/Train_Context_Relevance_Data.tsv\"],\n",
    "    \"validation_set\": [\"../datasets_file/output/Test_Context_Relevance_Data.tsv\"], \n",
    "    \"label_column\": [\"Context_Relevance_Label\"], \n",
    "    \"model_choice\": \"microsoft/deberta-v3-large\", # Default model is \"microsoft/deberta-v3-large\"\n",
    "    \"num_epochs\": 100, \n",
    "    \"patience_value\": 50, \n",
    "    \"learning_rate\": 1e-5,\n",
    "}\n",
    "\n",
    "ares = ARES(classifier_model=classifier_config)\n",
    "results = ares.train_classifier()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7589269",
   "metadata": {},
   "source": [
    "### Answer Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82a3a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///media/pc1/Ubuntu/Extend_Data/em_Thanh/Evaluation/ARES_evaluatione/code/mlruns/103283398758701508', creation_time=1749653950452, experiment_id='103283398758701508', last_update_time=1749653950452, lifecycle_stage='active', name='Answer_Relevance', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"Answer_Relevance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a1051e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: 'assigned_batch_size' not provided for classifier_model, using default value 1.\n",
      "\n",
      "Warning: 'gradient_accumulation_multiplier' not provided for classifier_model, using default value 32.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/132 [00:00<?, ? examples/s]Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 132/132 [00:00<00:00, 12672.19 examples/s]\n",
      "Map: 100%|██████████| 18/18 [00:00<00:00, 5415.11 examples/s]\n",
      "Map: 100%|██████████| 18/18 [00:00<00:00, 5153.06 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "Checkpoint Path: checkpoints/microsoft-deberta-v3-large/Answer_Relevance_Label_None_2025-06-11_22-01-19.pt\n",
      "Beginning Training\n",
      "Current Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:07<00:00, 18.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0/100] train_loss: 0.68832 valid_loss: 0.69768\n",
      "Validation loss decreased (inf --> 0.697677).  Saving model ...\n",
      "Current Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.41it/s]\n",
      "100%|██████████| 132/132 [00:07<00:00, 18.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/100] train_loss: 0.68913 valid_loss: 0.69567\n",
      "Validation loss decreased (0.697677 --> 0.695668).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:20<00:00,  1.13s/it]\n",
      "100%|██████████| 132/132 [00:07<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2/100] train_loss: 0.69447 valid_loss: 0.69264\n",
      "Validation loss decreased (0.695668 --> 0.692642).  Saving model ...\n",
      "Current Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:07<00:00,  2.32it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3/100] train_loss: 0.68886 valid_loss: 0.68801\n",
      "Validation loss decreased (0.692642 --> 0.688014).  Saving model ...\n",
      "Current Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:12<00:00,  1.40it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 18.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4/100] train_loss: 0.68082 valid_loss: 0.65763\n",
      "Validation loss decreased (0.688014 --> 0.657625).  Saving model ...\n",
      "Current Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:12<00:00,  1.42it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5/100] train_loss: 0.66556 valid_loss: 0.71790\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Current Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 66.91it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 18.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6/100] train_loss: 0.57653 valid_loss: 0.64184\n",
      "Validation loss decreased (0.657625 --> 0.641836).  Saving model ...\n",
      "Current Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:07<00:00,  2.42it/s]\n",
      "100%|██████████| 132/132 [00:07<00:00, 18.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7/100] train_loss: 0.38867 valid_loss: 0.55602\n",
      "Validation loss decreased (0.641836 --> 0.556017).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:15<00:00,  1.18it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8/100] train_loss: 0.21305 valid_loss: 0.71321\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Current Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 65.03it/s]\n",
      "100%|██████████| 132/132 [00:07<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9/100] train_loss: 0.10702 valid_loss: 0.94497\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Current Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 63.73it/s]\n",
      "100%|██████████| 132/132 [00:07<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10/100] train_loss: 0.05729 valid_loss: 1.16177\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Current Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 62.34it/s]\n",
      "100%|██████████| 132/132 [00:07<00:00, 18.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11/100] train_loss: 0.02772 valid_loss: 1.83857\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Current Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 63.47it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12/100] train_loss: 0.37752 valid_loss: 1.76167\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Current Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 67.50it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13/100] train_loss: 0.24900 valid_loss: 0.98436\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Current Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 67.19it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14/100] train_loss: 0.15177 valid_loss: 1.21624\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Current Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 67.23it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 15/100] train_loss: 0.12112 valid_loss: 1.19199\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Current Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 67.15it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 16/100] train_loss: 0.05012 valid_loss: 1.26789\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Current Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 67.17it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17/100] train_loss: 0.06036 valid_loss: 1.26165\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Current Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 67.48it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18/100] train_loss: 0.01480 valid_loss: 1.22075\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Current Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 67.43it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 19/100] train_loss: 0.07653 valid_loss: 1.21254\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Current Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 67.02it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20/100] train_loss: 0.13169 valid_loss: 1.32191\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Current Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 67.03it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21/100] train_loss: 0.29386 valid_loss: 1.55808\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Current Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 67.46it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22/100] train_loss: 0.14218 valid_loss: 0.92134\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Current Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 66.82it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23/100] train_loss: 0.19208 valid_loss: 0.85082\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Current Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 67.67it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24/100] train_loss: 0.10891 valid_loss: 1.40710\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Current Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 65.08it/s]\n",
      "100%|██████████| 132/132 [00:06<00:00, 19.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 25/100] train_loss: 0.08536 valid_loss: 1.12998\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Current Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 62.33it/s]\n",
      "100%|██████████| 132/132 [00:07<00:00, 18.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 26/100] train_loss: 0.04992 valid_loss: 1.52378\n",
      "EarlyStopping counter: 19 out of 20\n",
      "Current Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 62.99it/s]\n",
      "100%|██████████| 132/132 [00:07<00:00, 18.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 27/100] train_loss: 0.00778 valid_loss: 2.80753\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31m2025/06/11 22:06:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "100%|██████████| 18/18 [00:21<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Best Model\n",
      "Beginning Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 63.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Predictions and Reference Shapes\n",
      "torch.Size([18])\n",
      "torch.Size([18])\n",
      "Accuracy for Test Set: 0.7777777777777778\n",
      "Macro Precision: 86.67\n",
      "Macro Recall:    71.43\n",
      "Macro F1:        72.31\n",
      "Micro Precision: 77.78\n",
      "Micro Recall:    77.78\n",
      "Micro F1:        77.78\n",
      "Positive / Negative Reference Ratio: 0.389\n",
      "Saved classification checkpoint to: checkpoints/microsoft-deberta-v3-large/Answer_Relevance_Label_None_2025-06-11_22-01-19.pt\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifier_config = {\n",
    "    \"training_dataset\": [\"../datasets_file/output/Train_Answer_Relevance_Data.tsv\"],\n",
    "    \"validation_set\": [\"../datasets_file/output/Test_Answer_Relevance_Data.tsv\"], \n",
    "    \"label_column\": [\"Answer_Relevance_Label\"], \n",
    "    \"model_choice\": \"microsoft/deberta-v3-large\", # Default model is \"microsoft/deberta-v3-large\"\n",
    "    \"num_epochs\": 100, \n",
    "    \"patience_value\": 20, \n",
    "    \"learning_rate\": 1e-4,\n",
    "}\n",
    "\n",
    "ares = ARES(classifier_model=classifier_config)\n",
    "results = ares.train_classifier()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe329e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e641103",
   "metadata": {},
   "source": [
    "### Answer Faithfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fca86815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import mlflow\n",
    "\n",
    "# Step 1: Clear PyTorch cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Step 2: Run garbage collection to free up unused memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d12d55d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///media/pc1/Ubuntu/Extend_Data/em_Thanh/Evaluation/ARES_evaluatione/code/mlruns/420436849796807137', creation_time=1749654394585, experiment_id='420436849796807137', last_update_time=1749654394585, lifecycle_stage='active', name='Answer_Faithfulness', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Answer_Faithfulness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8a44b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: 'assigned_batch_size' not provided for classifier_model, using default value 1.\n",
      "\n",
      "Warning: 'gradient_accumulation_multiplier' not provided for classifier_model, using default value 32.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/128 [00:00<?, ? examples/s]Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 128/128 [00:00<00:00, 921.70 examples/s]\n",
      "Map: 100%|██████████| 16/16 [00:00<00:00, 818.51 examples/s]\n",
      "Map: 100%|██████████| 16/16 [00:00<00:00, 814.81 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "Checkpoint Path: checkpoints/microsoft-deberta-v3-large/Answer_Faithfulness_Label_None_2025-06-11_22-11-33.pt\n",
      "Beginning Training\n",
      "Current Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/128 [00:00<01:10,  1.81it/s]"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 47.50 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 186.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m classifier_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets_file/output/Train_Answer_Faithfulness_Data.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_set\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../datasets_file/output/Test_Answer_Faithfulness_Data.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     11\u001b[0m ares \u001b[38;5;241m=\u001b[39m ARES(classifier_model\u001b[38;5;241m=\u001b[39mclassifier_config)\n\u001b[0;32m---> 12\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mares\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/em_Thanh/Evaluation/ARES_evaluatione/ares/ares.py:139\u001b[0m, in \u001b[0;36mARES.train_classifier\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping binary classifier configuration due to missing parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[43mbinary_classifer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier_model_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/em_Thanh/Evaluation/ARES_evaluatione/ares/binary_classifier.py:90\u001b[0m, in \u001b[0;36mbinary_classifer_config\u001b[0;34m(training_dataset, validation_set, label_column, num_epochs, patience_value, learning_rate, training_dataset_path, validation_dataset_path, model_choice, assigned_batch_size, gradient_accumulation_multiplier, number_of_runs, num_warmup_steps, training_row_limit, validation_row_limit)\u001b[0m\n\u001b[1;32m     73\u001b[0m tokenized_datasets \u001b[38;5;241m=\u001b[39m initalize_dataset_for_tokenization(tokenizer, training_dataset_arrow, validation_dataset_arrow, test_dataset_arrow)\n\u001b[1;32m     75\u001b[0m train_and_eval_settings \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber_of_runs\u001b[39m\u001b[38;5;124m\"\u001b[39m: number_of_runs,\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenized_datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m: tokenized_datasets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradient_accumulation_multiplier\u001b[39m\u001b[38;5;124m\"\u001b[39m: gradient_accumulation_multiplier\n\u001b[1;32m     88\u001b[0m }\n\u001b[0;32m---> 90\u001b[0m model, avg_train_losses, avg_valid_losses, eval_dataloader, inference_times \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_and_eval_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m total_predictions, total_references, metric \u001b[38;5;241m=\u001b[39m evaluate_model(model, model_choice, checkpoint_path, device, eval_dataloader, inference_times)\n\u001b[1;32m     94\u001b[0m print_and_save_model(total_predictions, total_references, checkpoint_path, metric)\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/em_Thanh/Evaluation/ARES_evaluatione/ares/LLM_as_a_Judge_Adaptation/General_Binary_Classifier.py:836\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    833\u001b[0m     new_batch \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m'\u001b[39m: batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m: batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)}\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 836\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m    838\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/em_Thanh/Evaluation/ARES_evaluatione/ares/LLM_as_a_Judge_Adaptation/General_Binary_Classifier.py:237\u001b[0m, in \u001b[0;36mCustomBERTModel.forward\u001b[0;34m(self, ids, mask, labels, decoder_input_ids)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# Perform a forward pass for other models\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     total_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoderModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m total_output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_hidden_state\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# Format the last hidden state and pass it through the classifier\u001b[39;00m\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:796\u001b[0m, in \u001b[0;36mDebertaV2Model.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    786\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    788\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    789\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    790\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    793\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    794\u001b[0m )\n\u001b[0;32m--> 796\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    803\u001b[0m encoded_layers \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:669\u001b[0m, in \u001b[0;36mDebertaV2Encoder.forward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    659\u001b[0m     output_states, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    660\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    661\u001b[0m         next_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    666\u001b[0m         output_attentions,\n\u001b[1;32m    667\u001b[0m     )\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m     output_states, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    679\u001b[0m     all_attentions \u001b[38;5;241m=\u001b[39m all_attentions \u001b[38;5;241m+\u001b[39m (attn_weights,)\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:437\u001b[0m, in \u001b[0;36mDebertaV2Layer.forward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    430\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    435\u001b[0m     output_attentions: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    436\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, Optional[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m--> 437\u001b[0m     attention_output, att_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m    446\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:370\u001b[0m, in \u001b[0;36mDebertaV2Attention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    363\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m     rel_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    369\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, Optional[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m--> 370\u001b[0m     self_output, att_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m         query_states \u001b[38;5;241m=\u001b[39m hidden_states\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:250\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_attention:\n\u001b[1;32m    249\u001b[0m     rel_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_dropout(rel_embeddings)\n\u001b[0;32m--> 250\u001b[0m     rel_att \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisentangled_attention_bias\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rel_att \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m rel_att\n",
      "File \u001b[0;32m/media/pc1/Ubuntu/Extend_Data/anaconda3/envs/ares_thanh/lib/python3.9/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:329\u001b[0m, in \u001b[0;36mDisentangledSelfAttention.disentangled_attention_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    323\u001b[0m     c2p_pos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(relative_pos \u001b[38;5;241m+\u001b[39m att_span, \u001b[38;5;241m0\u001b[39m, att_span \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    324\u001b[0m     c2p_att \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    325\u001b[0m         c2p_att,\n\u001b[1;32m    326\u001b[0m         dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    327\u001b[0m         index\u001b[38;5;241m=\u001b[39mc2p_pos\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand([query_layer\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), query_layer\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), relative_pos\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)]),\n\u001b[1;32m    328\u001b[0m     )\n\u001b[0;32m--> 329\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mc2p_att\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc2p_att\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# position->content\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp2c\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_att_type:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 230.00 MiB. GPU 0 has a total capacity of 23.68 GiB of which 47.50 MiB is free. Including non-PyTorch memory, this process has 23.21 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 186.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "classifier_config = {\n",
    "    \"training_dataset\": [\"../datasets_file/output/Train_Answer_Faithfulness_Data.tsv\"],\n",
    "    \"validation_set\": [\"../datasets_file/output/Test_Answer_Faithfulness_Data.tsv\"], \n",
    "    \"label_column\": [\"Answer_Faithfulness_Label\"], \n",
    "    \"model_choice\": \"microsoft/deberta-v3-large\", # Default model is \"microsoft/deberta-v3-large\"\n",
    "    \"num_epochs\": 100, \n",
    "    \"patience_value\": 20, \n",
    "    \"learning_rate\": 1e-4,\n",
    "}\n",
    "\n",
    "ares = ARES(classifier_model=classifier_config)\n",
    "results = ares.train_classifier()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b141200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65363a",
   "metadata": {},
   "source": [
    "### Longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9794b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/11 21:00:57 INFO mlflow.tracking.fluent: Experiment with name 'Clinical-Longformer' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///media/pc1/Ubuntu/Extend_Data/em_Thanh/Evaluation/ARES_evaluatione/code/mlruns/405740623811598206', creation_time=1749650457366, experiment_id='405740623811598206', last_update_time=1749650457366, lifecycle_stage='active', name='Clinical-Longformer', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"Clinical-Longformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1442bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Warning: 'assigned_batch_size' not provided for classifier_model, using default value 1.\n",
      "\n",
      "Warning: 'gradient_accumulation_multiplier' not provided for classifier_model, using default value 32.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 218/218 [00:00<00:00, 1215.26 examples/s]\n",
      "Map: 100%|██████████| 29/29 [00:00<00:00, 1185.59 examples/s]\n",
      "Map: 100%|██████████| 29/29 [00:00<00:00, 1162.97 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerModel were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint Path: checkpoints/yikuan8-Clinical-Longformer/Context_Relevance_Label_None_2025-06-11_21-01-01.pt\n",
      "Beginning Training\n",
      "Current Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 218/218 [01:37<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0/50] train_loss: 0.69607 valid_loss: 0.70103\n",
      "Validation loss decreased (inf --> 0.701032).  Saving model ...\n",
      "Current Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:06<00:00,  4.76it/s]\n",
      "100%|██████████| 218/218 [01:35<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/50] train_loss: 0.69801 valid_loss: 0.68705\n",
      "Validation loss decreased (0.701032 --> 0.687046).  Saving model ...\n",
      "Current Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:06<00:00,  4.75it/s]\n",
      "100%|██████████| 218/218 [01:35<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2/50] train_loss: 0.69075 valid_loss: 0.68795\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Current Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.84it/s]\n",
      "100%|██████████| 218/218 [01:35<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3/50] train_loss: 0.69065 valid_loss: 0.70597\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Current Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.54it/s]\n",
      "100%|██████████| 218/218 [01:36<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4/50] train_loss: 0.69166 valid_loss: 0.70737\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Current Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.89it/s]\n",
      "100%|██████████| 218/218 [01:36<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5/50] train_loss: 0.68854 valid_loss: 0.68802\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Current Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.80it/s]\n",
      "100%|██████████| 218/218 [01:36<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6/50] train_loss: 0.67791 valid_loss: 0.71344\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Current Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.84it/s]\n",
      "100%|██████████| 218/218 [01:36<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7/50] train_loss: 0.65385 valid_loss: 0.78694\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Current Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.81it/s]\n",
      "100%|██████████| 218/218 [01:36<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8/50] train_loss: 0.58520 valid_loss: 0.80461\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Current Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.62it/s]\n",
      "100%|██████████| 218/218 [01:36<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9/50] train_loss: 0.51638 valid_loss: 1.02273\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Current Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.56it/s]\n",
      "100%|██████████| 218/218 [01:36<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/50] train_loss: 0.48824 valid_loss: 0.64329\n",
      "Validation loss decreased (0.687046 --> 0.643288).  Saving model ...\n",
      "Current Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:06<00:00,  4.49it/s]\n",
      "100%|██████████| 218/218 [01:36<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/50] train_loss: 0.52487 valid_loss: 0.62715\n",
      "Validation loss decreased (0.643288 --> 0.627152).  Saving model ...\n",
      "Current Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:06<00:00,  4.75it/s]\n",
      "100%|██████████| 218/218 [01:38<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/50] train_loss: 0.51221 valid_loss: 0.93199\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Current Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.10it/s]\n",
      "100%|██████████| 218/218 [01:39<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/50] train_loss: 0.47576 valid_loss: 0.75730\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Current Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.29it/s]\n",
      "100%|██████████| 218/218 [01:39<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/50] train_loss: 0.45338 valid_loss: 0.70363\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Current Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.49it/s]\n",
      "100%|██████████| 218/218 [01:39<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/50] train_loss: 0.37326 valid_loss: 0.88231\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Current Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.27it/s]\n",
      "100%|██████████| 218/218 [01:39<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/50] train_loss: 0.24453 valid_loss: 1.20289\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Current Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.10it/s]\n",
      "100%|██████████| 218/218 [01:39<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/50] train_loss: 0.19739 valid_loss: 1.34856\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Current Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.41it/s]\n",
      "100%|██████████| 218/218 [01:38<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/50] train_loss: 0.14441 valid_loss: 1.63876\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Current Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.94it/s]\n",
      "100%|██████████| 218/218 [01:35<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/50] train_loss: 0.11359 valid_loss: 1.72529\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Current Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.94it/s]\n",
      "100%|██████████| 218/218 [01:34<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/50] train_loss: 0.13936 valid_loss: 2.42062\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Current Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.95it/s]\n",
      "100%|██████████| 218/218 [01:34<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/50] train_loss: 0.17629 valid_loss: 1.63064\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31m2025/06/11 21:39:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "100%|██████████| 29/29 [00:15<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Best Model\n",
      "Beginning Evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "Predictions and Reference Shapes\n",
      "torch.Size([29])\n",
      "torch.Size([29])\n",
      "Accuracy for Test Set: 0.5172413793103449\n",
      "Macro Precision: 52.14\n",
      "Macro Recall:    52.27\n",
      "Macro F1:        51.20\n",
      "Micro Precision: 51.72\n",
      "Micro Recall:    51.72\n",
      "Micro F1:        51.72\n",
      "Positive / Negative Reference Ratio: 0.379\n",
      "Saved classification checkpoint to: checkpoints/yikuan8-Clinical-Longformer/Context_Relevance_Label_None_2025-06-11_21-01-01.pt\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifier_config = {\n",
    "    \"training_dataset\": [\"../datasets_file/output/Train_Context_Relevance_Data.tsv\"],\n",
    "    \"validation_set\": [\"../datasets_file/output/Test_Context_Relevance_Data.tsv\"], \n",
    "    \"label_column\": [\"Context_Relevance_Label\"], \n",
    "    \"model_choice\": \"yikuan8/Clinical-Longformer\", # Default model is \"microsoft/deberta-v3-large\"\n",
    "    \"num_epochs\": 100, \n",
    "    \"patience_value\": 20, \n",
    "    \"learning_rate\": 1e-4\n",
    "}\n",
    "\n",
    "ares_ClinicalBERT = ARES(classifier_model=classifier_config)\n",
    "results_ClinicalBERT = ares_ClinicalBERT.train_classifier()\n",
    "print(results_ClinicalBERT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714ccd9",
   "metadata": {},
   "source": [
    "### Answer Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a490e83",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ares_thanh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
